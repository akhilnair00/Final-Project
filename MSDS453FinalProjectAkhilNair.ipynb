{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSDS 453 - Final Project\n",
    "Summer 2024\n",
    "Akhilesh Nair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import sklearn\n",
    "import transformers\n",
    "import torch\n",
    "import re\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from transformers import BertForSequenceClassification, AdamW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in google dataset: GeoEmotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = pd.read_csv('https://storage.googleapis.com/gresearch/goemotions/data/full_dataset/goemotions_1.csv')\n",
    "dataset2 = pd.read_csv('https://storage.googleapis.com/gresearch/goemotions/data/full_dataset/goemotions_2.csv')\n",
    "dataset3 = pd.read_csv('https://storage.googleapis.com/gresearch/goemotions/data/full_dataset/goemotions_3.csv')\n",
    "\n",
    "frame = [dataset1, dataset2, dataset3]\n",
    "full_data = pd.concat(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 211225 entries, 0 to 71224\n",
      "Data columns (total 37 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   text                  211225 non-null  object \n",
      " 1   id                    211225 non-null  object \n",
      " 2   author                211225 non-null  object \n",
      " 3   subreddit             211225 non-null  object \n",
      " 4   link_id               211225 non-null  object \n",
      " 5   parent_id             211225 non-null  object \n",
      " 6   created_utc           211225 non-null  float64\n",
      " 7   rater_id              211225 non-null  int64  \n",
      " 8   example_very_unclear  211225 non-null  bool   \n",
      " 9   admiration            211225 non-null  int64  \n",
      " 10  amusement             211225 non-null  int64  \n",
      " 11  anger                 211225 non-null  int64  \n",
      " 12  annoyance             211225 non-null  int64  \n",
      " 13  approval              211225 non-null  int64  \n",
      " 14  caring                211225 non-null  int64  \n",
      " 15  confusion             211225 non-null  int64  \n",
      " 16  curiosity             211225 non-null  int64  \n",
      " 17  desire                211225 non-null  int64  \n",
      " 18  disappointment        211225 non-null  int64  \n",
      " 19  disapproval           211225 non-null  int64  \n",
      " 20  disgust               211225 non-null  int64  \n",
      " 21  embarrassment         211225 non-null  int64  \n",
      " 22  excitement            211225 non-null  int64  \n",
      " 23  fear                  211225 non-null  int64  \n",
      " 24  gratitude             211225 non-null  int64  \n",
      " 25  grief                 211225 non-null  int64  \n",
      " 26  joy                   211225 non-null  int64  \n",
      " 27  love                  211225 non-null  int64  \n",
      " 28  nervousness           211225 non-null  int64  \n",
      " 29  optimism              211225 non-null  int64  \n",
      " 30  pride                 211225 non-null  int64  \n",
      " 31  realization           211225 non-null  int64  \n",
      " 32  relief                211225 non-null  int64  \n",
      " 33  remorse               211225 non-null  int64  \n",
      " 34  sadness               211225 non-null  int64  \n",
      " 35  surprise              211225 non-null  int64  \n",
      " 36  neutral               211225 non-null  int64  \n",
      "dtypes: bool(1), float64(1), int64(29), object(6)\n",
      "memory usage: 59.8+ MB\n"
     ]
    }
   ],
   "source": [
    "full_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert text to lowercase while also removing special char, nums and punctuation\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "full_data['cleaned_text'] = full_data['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>rater_id</th>\n",
       "      <th>example_very_unclear</th>\n",
       "      <th>admiration</th>\n",
       "      <th>...</th>\n",
       "      <th>nervousness</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pride</th>\n",
       "      <th>realization</th>\n",
       "      <th>relief</th>\n",
       "      <th>remorse</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That game hurt.</td>\n",
       "      <td>eew5j0j</td>\n",
       "      <td>Brdd9</td>\n",
       "      <td>nrl</td>\n",
       "      <td>t3_ajis4z</td>\n",
       "      <td>t1_eew18eq</td>\n",
       "      <td>1.548381e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>that game hurt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&gt;sexuality shouldn’t be a grouping category I...</td>\n",
       "      <td>eemcysk</td>\n",
       "      <td>TheGreen888</td>\n",
       "      <td>unpopularopinion</td>\n",
       "      <td>t3_ai4q37</td>\n",
       "      <td>t3_ai4q37</td>\n",
       "      <td>1.548084e+09</td>\n",
       "      <td>37</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sexuality shouldn t be a grouping category it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You do right, if you don't care then fuck 'em!</td>\n",
       "      <td>ed2mah1</td>\n",
       "      <td>Labalool</td>\n",
       "      <td>confessions</td>\n",
       "      <td>t3_abru74</td>\n",
       "      <td>t1_ed2m7g7</td>\n",
       "      <td>1.546428e+09</td>\n",
       "      <td>37</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>you do right if you don t care then fuck em</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Man I love reddit.</td>\n",
       "      <td>eeibobj</td>\n",
       "      <td>MrsRobertshaw</td>\n",
       "      <td>facepalm</td>\n",
       "      <td>t3_ahulml</td>\n",
       "      <td>t3_ahulml</td>\n",
       "      <td>1.547965e+09</td>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>man i love reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[NAME] was nowhere near them, he was by the Fa...</td>\n",
       "      <td>eda6yn6</td>\n",
       "      <td>American_Fascist713</td>\n",
       "      <td>starwarsspeculation</td>\n",
       "      <td>t3_ackt2f</td>\n",
       "      <td>t1_eda65q2</td>\n",
       "      <td>1.546669e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>name was nowhere near them he was by the falcon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       id  \\\n",
       "0                                    That game hurt.  eew5j0j   \n",
       "1   >sexuality shouldn’t be a grouping category I...  eemcysk   \n",
       "2     You do right, if you don't care then fuck 'em!  ed2mah1   \n",
       "3                                 Man I love reddit.  eeibobj   \n",
       "4  [NAME] was nowhere near them, he was by the Fa...  eda6yn6   \n",
       "\n",
       "                author            subreddit    link_id   parent_id  \\\n",
       "0                Brdd9                  nrl  t3_ajis4z  t1_eew18eq   \n",
       "1          TheGreen888     unpopularopinion  t3_ai4q37   t3_ai4q37   \n",
       "2             Labalool          confessions  t3_abru74  t1_ed2m7g7   \n",
       "3        MrsRobertshaw             facepalm  t3_ahulml   t3_ahulml   \n",
       "4  American_Fascist713  starwarsspeculation  t3_ackt2f  t1_eda65q2   \n",
       "\n",
       "    created_utc  rater_id  example_very_unclear  admiration  ...  nervousness  \\\n",
       "0  1.548381e+09         1                 False           0  ...            0   \n",
       "1  1.548084e+09        37                  True           0  ...            0   \n",
       "2  1.546428e+09        37                 False           0  ...            0   \n",
       "3  1.547965e+09        18                 False           0  ...            0   \n",
       "4  1.546669e+09         2                 False           0  ...            0   \n",
       "\n",
       "   optimism  pride  realization  relief  remorse  sadness  surprise  neutral  \\\n",
       "0         0      0            0       0        0        1         0        0   \n",
       "1         0      0            0       0        0        0         0        0   \n",
       "2         0      0            0       0        0        0         0        1   \n",
       "3         0      0            0       0        0        0         0        0   \n",
       "4         0      0            0       0        0        0         0        1   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0                                    that game hurt   \n",
       "1   sexuality shouldn t be a grouping category it...  \n",
       "2       you do right if you don t care then fuck em   \n",
       "3                                 man i love reddit   \n",
       "4   name was nowhere near them he was by the falcon   \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's drop all the useless columns, like the author, time created, rater approval, link_id, parent_id, rater_id etc... I will keep the subreddit for reference though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.drop(['id', 'author', 'link_id', 'parent_id', 'created_utc', 'rater_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>example_very_unclear</th>\n",
       "      <th>admiration</th>\n",
       "      <th>amusement</th>\n",
       "      <th>anger</th>\n",
       "      <th>annoyance</th>\n",
       "      <th>approval</th>\n",
       "      <th>caring</th>\n",
       "      <th>confusion</th>\n",
       "      <th>...</th>\n",
       "      <th>nervousness</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pride</th>\n",
       "      <th>realization</th>\n",
       "      <th>relief</th>\n",
       "      <th>remorse</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That game hurt.</td>\n",
       "      <td>nrl</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>that game hurt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&gt;sexuality shouldn’t be a grouping category I...</td>\n",
       "      <td>unpopularopinion</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sexuality shouldn t be a grouping category it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You do right, if you don't care then fuck 'em!</td>\n",
       "      <td>confessions</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>you do right if you don t care then fuck em</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Man I love reddit.</td>\n",
       "      <td>facepalm</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>man i love reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[NAME] was nowhere near them, he was by the Fa...</td>\n",
       "      <td>starwarsspeculation</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>name was nowhere near them he was by the falcon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text            subreddit  \\\n",
       "0                                    That game hurt.                  nrl   \n",
       "1   >sexuality shouldn’t be a grouping category I...     unpopularopinion   \n",
       "2     You do right, if you don't care then fuck 'em!          confessions   \n",
       "3                                 Man I love reddit.             facepalm   \n",
       "4  [NAME] was nowhere near them, he was by the Fa...  starwarsspeculation   \n",
       "\n",
       "   example_very_unclear  admiration  amusement  anger  annoyance  approval  \\\n",
       "0                 False           0          0      0          0         0   \n",
       "1                  True           0          0      0          0         0   \n",
       "2                 False           0          0      0          0         0   \n",
       "3                 False           0          0      0          0         0   \n",
       "4                 False           0          0      0          0         0   \n",
       "\n",
       "   caring  confusion  ...  nervousness  optimism  pride  realization  relief  \\\n",
       "0       0          0  ...            0         0      0            0       0   \n",
       "1       0          0  ...            0         0      0            0       0   \n",
       "2       0          0  ...            0         0      0            0       0   \n",
       "3       0          0  ...            0         0      0            0       0   \n",
       "4       0          0  ...            0         0      0            0       0   \n",
       "\n",
       "   remorse  sadness  surprise  neutral  \\\n",
       "0        0        1         0        0   \n",
       "1        0        0         0        0   \n",
       "2        0        0         0        1   \n",
       "3        0        0         0        0   \n",
       "4        0        0         0        1   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0                                    that game hurt   \n",
       "1   sexuality shouldn t be a grouping category it...  \n",
       "2       you do right if you don t care then fuck em   \n",
       "3                                 man i love reddit   \n",
       "4   name was nowhere near them he was by the falcon   \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the data is already encoded via one hot encoding, we can move on to splitting the test and train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_columns = [col for col in full_data.columns[3:31]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = full_data['cleaned_text']\n",
    "y = full_data[emotion_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 168980 samples\n",
      "Testing set size: 42245 samples\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us tokenize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90bfd05a668f4875a0f47a64053f8a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akhil\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\akhil\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93793a35b8540d785162fcb5a7d5462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "557fa535464d45dc8483aed6cdfb9402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8462327c257e4abcb88cc126a5a86c50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akhil\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize the text data\n",
    "train_encodings = tokenizer(list(X_train), truncation=True, padding=True, max_length=128)\n",
    "test_encodings = tokenizer(list(X_test), truncation=True, padding=True, max_length=128)\n",
    "\n",
    "\n",
    "train_encodings = {key: torch.tensor(val) for key, val in train_encodings.items()}\n",
    "test_encodings = {key: torch.tensor(val) for key, val in test_encodings.items()}\n",
    "\n",
    "train_labels = torch.tensor(y_train.values)\n",
    "test_labels = torch.tensor(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TensorDataset directly\n",
    "train_dataset = TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], train_labels)\n",
    "test_dataset = TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'], test_labels)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data is good and ready, let's start training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ccb1bc86b58438c9beb529061b785cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=28, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=y_train.shape[1])\n",
    "\n",
    "# This will move us to the gpu --- THIS DOES NOT MOVE US TO THE GPU\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akhil\\anaconda3\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras import layers, regularizers\n",
    "\n",
    "# k.clear_session()\n",
    "# inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
    "# embedded = layers.Embedding(input_dim=max_tokens, output_dim=256, mask_zero=True)(inputs)\n",
    "# x = layers.LSTM(\n",
    "#     32,\n",
    "#     kernel_regularizer=regularizers.l2(0.01)\n",
    "# )(embedded)\n",
    "# x = layers.Dropout(0.5)(x)  #\n",
    "# outputs = layers.Dense(4, activation=\"softmax\")(x)\n",
    "# model = tf.keras.Model(inputs, outputs)\n",
    "# model.compile(optimizer=\"rmsprop\",\n",
    "#               loss=\"SparseCategoricalCrossentropy\",\n",
    "#               metrics=[\"accuracy\"])\n",
    "# model.summary()\n",
    "\n",
    "# callbacks = [\n",
    "#     tf.keras.callbacks.ModelCheckpoint(\"LSTM_L2_Dropout.keras\", save_best_only=True),\n",
    "#     tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\n",
    "# ]\n",
    "# history = model.fit(int_train_ds, validation_data=int_val_ds, epochs=200, callbacks=callbacks)\n",
    "# model = keras.models.load_model(\"LSTM_L2_Dropout.keras\")\n",
    "# print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "False\n",
      "None\n",
      "in the while loop\n",
      "enter loop 1\n",
      "exit loop 1\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n",
      "exit loop 2\n",
      "enter loop 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[0;32m     32\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 33\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     34\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     36\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[1;32m--> 521\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    522\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    523\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m _engine_run_backward(\n\u001b[0;32m    290\u001b[0m     tensors,\n\u001b[0;32m    291\u001b[0m     grad_tensors_,\n\u001b[0;32m    292\u001b[0m     retain_graph,\n\u001b[0;32m    293\u001b[0m     create_graph,\n\u001b[0;32m    294\u001b[0m     inputs,\n\u001b[0;32m    295\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    296\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    297\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\autograd\\graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    769\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    770\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Ensure you're using the right loss function for multi-label classification\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# During training\n",
    "with tf.device('/device:GPU:0'):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    print(torch.cuda.is_available())  # This should return True if GPU is accessible\n",
    "    print(torch.version.cuda)  # This should return the CUDA version PyTorch is using\n",
    "    print('in the while loop')\n",
    "    for epoch in range(3):\n",
    "        print('enter loop 1')\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        print('exit loop 1')\n",
    "        for batch in train_loader:\n",
    "            print('enter loop 2')\n",
    "            # Move batch to device\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            input_ids, attention_mask, labels = batch\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = loss_fn(logits, labels.float())  # Make sure labels are in the correct format (float)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            print('exit loop 2')\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}\")\n",
    "print('out of the while loop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason, I couldn't switch the processing device for the tensor stuff to the GPU. The fitting time was running upwards of 5 hours when I decided to stop it. I think it would have gone for many 100+ hours. I have way too many data points, will have to take a subset to train the model. Another option is to do a smaller scale version of BERT, known as distillBERT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
